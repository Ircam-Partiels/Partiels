{
  "models": [
    {
      // Too Small Context Length
      "name": "Llama-3.1-8B-Instruct-Q4_K_M",
      "model": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
      "template": "https://raw.githubusercontent.com/ggml-org/llama.cpp/refs/heads/master/models/templates/meta-llama-Llama-3.1-8B-Instruct.jinja",
      "adjective": "expressive",
      "n_ctx": 16384,
      "n_batch": 4096
    },
    {
      // Too Small Context Length
      "name": "Phi-3.5-mini-instruct-q4_k_m",
      "model": "https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-Q4_K_M.gguf",
      "tokenizer": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct/resolve/main/tokenizer_config.json",
      "adjective": "lightweight",
      "n_ctx": 4096,
      "n_batch": 512
    },
    {
      // Template does not support MCP
      "name": "Qwen2.5-Coder-7B-Instruct-Q4_K_M",
      "model": "https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct-GGUF/resolve/main/qwen2.5-coder-7b-instruct-q4_k_m.gguf",
      "tokenizer": "https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct/resolve/main/tokenizer_config.json",
      "adjective": "reliable",
      "n_ctx": 12288,
      "n_batch": 1536
    },
    {
      // Too Large Model File
      "name": "Llama-3.3-70B-Instruct-Q4_K_M",
      "model": "https://huggingface.co/bartowski/Llama-3.3-70B-Instruct-GGUF/resolve/main/Llama-3.3-70B-Instruct-Q4_K_M.gguf",
      "template": "https://raw.githubusercontent.com/ggml-org/llama.cpp/refs/heads/master/models/templates/meta-llama-Llama-3.3-70B-Instruct.jinja",
      "adjective": "powerful",
      "n_ctx": 32768,
      "n_batch": 4096
    },
    {
      // MCP support is poor
      "name": "mistral-7b-instruct-v0.3-q4_k_m",
      "model": "https://huggingface.co/jfer1015/Mistral-7B-Instruct-v0.3-Q4_K_M-GGUF/resolve/main/mistral-7b-instruct-v0.3-q4_k_m.gguf",
      "tokenizer": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/resolve/main/tokenizer_config.json",
      "adjective": "predictable",
      "n_ctx": 8192,
      "n_batch": 2048
    },
    {
      // Unsupported Model Format
      "name": "QwQ-32B-Q4_K_M",
      "model": "https://huggingface.co/Qwen/QwQ-32B-GGUF/resolve/main/qwq-32b-q4_k_m.gguf",
      "tokenizer": "https://huggingface.co/Qwen/QwQ-32B/resolve/main/tokenizer_config.json",
      "adjective": "advanced",
      "n_ctx": 32768,
      "n_batch": 8192
    },
    {
      // Unsupported Model Format
      "name": "GLM-4.7-Flash-Q4_K_M",
      "model": "https://huggingface.co/unsloth/GLM-4.7-Flash-GGUF/resolve/main/GLM-4.7-Flash-Q4_K_M.gguf",
      "template": "https://huggingface.co/zai-org/GLM-4.7-Flash/resolve/main/chat_template.jinja",
      "adjective": "versatile",
      "n_ctx": 32768,
      "n_batch": 8192
    }
  ]
}
